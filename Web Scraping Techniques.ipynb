{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce7ce35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# import selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f949838a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095ef1a8",
   "metadata": {},
   "source": [
    "# Scraping Job Opportunity in LinkedIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc33b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_text = requests.get('https://www.linkedin.com/jobs/search/?currentJobId=3646641361&keywords=python&origin=JOB_COLLECTION_PAGE_SEARCH_BUTTON&refresh=true').text\n",
    "\n",
    "soup = BeautifulSoup(html_text, 'html.parser')\n",
    "\n",
    "jobs = soup.find_all('li', class_='''ember-view''')\n",
    "for job in jobs:\n",
    "    print(job)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154251aa",
   "metadata": {},
   "source": [
    "# Scraping Job Opportunity in timesjobs.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabccf93",
   "metadata": {},
   "source": [
    "## Without any Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6064c899",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_text = requests.get('https://www.timesjobs.com/candidate/job-search.html?searchType=personalizedSearch&from=submit&txtKeywords=python&txtLocation=').text\n",
    "\n",
    "soup = BeautifulSoup(html_text, 'html.parser')\n",
    "\n",
    "jobs = soup.find_all('li', class_='clearfix job-bx wht-shd-bx')\n",
    "\n",
    "job_posts = pd.DataFrame()\n",
    "\n",
    "for job in jobs:\n",
    "    company = job.find('h3', class_='joblist-comp-name').text.strip().upper()\n",
    "    position = job.find('a', target='_blank').text.strip()\n",
    "    skills = job.find('span', class_='srp-skills').text.strip().split('  ,  ')\n",
    "    posted = job.find('span', class_='sim-posted').text.strip()\n",
    "    more_info = job.header.h2.a['href']\n",
    "    job_post = pd.DataFrame([[company, position, skills, posted, more_info]], columns=['Company', 'Position', 'Skills', 'Posted', 'More Info'], index=[0])\n",
    "    job_posts = job_posts.append(job_post, ignore_index=True)\n",
    "\n",
    "print('This is the result of scraping TimesJobs.com')\n",
    "display(job_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a927e146",
   "metadata": {},
   "source": [
    "## With Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9c68b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_text = requests.get('https://www.timesjobs.com/candidate/job-search.html?from=submit&luceneResultSize=25&txtKeywords=python&postWeek=60&searchType=personalizedSearch&actualTxtKeywords=python&searchBy=0&rdoOperator=OR&pDate=I&sequence=1&startPage=1').text\n",
    "soup = BeautifulSoup(html_text, 'html.parser')\n",
    "jobs = soup.find_all('li', class_='clearfix job-bx wht-shd-bx')\n",
    "job_posts = pd.DataFrame()\n",
    "for job in jobs:\n",
    "    posted = job.find('span', class_='sim-posted').text.strip()\n",
    "    if 'few' not in posted:\n",
    "        company = job.find('h3', class_='joblist-comp-name').text.strip().upper()\n",
    "        position = job.find('a', target='_blank').text.strip()\n",
    "        skills = job.find('span', class_='srp-skills').text.strip().split('  ,  ')\n",
    "        more_info = job.header.h2.a['href']\n",
    "        job_post = pd.DataFrame([[company, position, skills, posted, more_info]], columns=['Company', 'Position', 'Skills', 'Posted', 'More Info'], index=[0])\n",
    "        job_posts = job_posts.append(job_post, ignore_index=True)\n",
    "\n",
    "print('This is the result of scraping TimesJobs.com')\n",
    "display(job_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc71955",
   "metadata": {},
   "source": [
    "## Looping through pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43596ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_text = requests.get('https://www.timesjobs.com/candidate/job-search.html?from=submit&luceneResultSize=25&txtKeywords=python&postWeek=60&searchType=personalizedSearch&actualTxtKeywords=python&searchBy=0&rdoOperator=OR&pDate=I&sequence=1&startPage=1').text\n",
    "soup = BeautifulSoup(html_text, 'html.parser')\n",
    "pages = soup.find('div', {'class':'srp-pagination clearfix'})\n",
    "job_posts = pd.DataFrame()\n",
    "page_now = 1\n",
    "for page in pages:\n",
    "    html_text = requests.get(f'https://www.timesjobs.com/candidate/job-search.html?from=submit&luceneResultSize=25&txtKeywords=python&postWeek=60&searchType=personalizedSearch&actualTxtKeywords=python&searchBy=0&rdoOperator=OR&pDate=I&sequence={page_now}&startPage=1').text\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    jobs = soup.find_all('li', class_='clearfix job-bx wht-shd-bx')\n",
    "    if 'Next' not in page.text.strip():\n",
    "        for job in jobs:\n",
    "            posted = job.find('span', class_='sim-posted').text.strip()\n",
    "            company = job.find('h3', class_='joblist-comp-name').text.strip().upper()\n",
    "            position = job.find('a', target='_blank').text.strip()\n",
    "            skills = job.find('span', class_='srp-skills').text.strip().split('  ,  ')\n",
    "            more_info = job.header.h2.a['href']\n",
    "            job_post = pd.DataFrame([[company, position, skills, posted, more_info]], columns=['Company', 'Position', 'Skills', 'Posted', 'More Info'], index=[0])\n",
    "            job_post['Page'] = page_now\n",
    "            job_posts = job_posts.append(job_post, ignore_index=True)\n",
    "    else:\n",
    "        break\n",
    "    page_now+=1\n",
    "\n",
    "print('This is the result of scraping TimesJobs.com')\n",
    "display(job_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53e88cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
